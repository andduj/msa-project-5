### Название задачи: Внедрение пакетной обработки и мониторинга для TradeWare (Spring Batch как ETL-движок)
### Автор: <указать>
### Дата: <указать>

### Функциональные требования
| № | Акторы/системы | Use Case | Описание |
| :-: | :- | :- | :- |
| 1 | Сотрудник склада, Web UI | Загрузка отчёта CSV | Пользователь загружает CSV; файл сохраняется; запускается пакетная обработка |
| 2 | Batch ETL | Валидация | Проверка формата/целостности, быстрый фэйл при ошибках |
| 3 | Batch ETL | Обогащение данными | Джойны со справочниками, применение промо/акций |
| 4 | Batch ETL | Запись в результирующие таблицы | Пакетная запись с транзакциями/ретраями |
| 5 | Observability | Логи/метрики/трейсы | Централизованный сбор и алертинг |

### Нефункциональные требования
| № | Требование |
| :-: | :- |
| 1 | Производительность: ≤ 30 сек на 2 000 строк; масштаб до 100–150 параллельных загрузок |
| 2 | Надёжность: атомарность шагов, идемпотентность, ретраи |
| 3 | Масштабируемость: горизонтальный скейл воркеров/шардирование файлов |
| 4 | Наблюдаемость: метрики (Prometheus), логи (ELK/Loki), трассировки (OTel) |
| 5 | Совместимость: интеграция с Java 11/WildFly, PostgreSQL, GCS |

### Решение
Используем Spring Batch как фреймворк для пакетной обработки: Reader/Processor/Writer, Job/Step, Chunk‑processing, Retry/Skip, JobRepository. Выносим batch в отдельный сервис рядом с монолитом. Триггерим Job загрузкой файла или расписанием. Храним исходные файлы в GCS, метаданные Job в PostgreSQL.

Ключевые элементы:
- Batch Service (Spring Boot + Spring Batch):
  - ItemReader: GCS → stream CSV; Validation Processor; Enrichment Processor (JDBC/Feign);
  - ItemWriter: JDBC batch → результирующие таблицы;
  - Partitioning: разбиение по чанкам/файлам для параллелизма; Retry/Skip по полям/строкам;
  - JobRepository: PostgreSQL с префиксом BATCH_;
- Orchestration: k8s CronJob для ночных задач; REST endpoint для триггера загрузок из UI;
- Storage: GCS для исходных файлов; БД номенклатуры PostgreSQL;
- Observability: Micrometer → Prometheus/Grafana; stdout → ELK/Loki; OpenTelemetry трассировки.

Диаграммы C4 см. в `task-4/results/C4-ToBe-Context.puml` и `task-4/results/C4-ToBe-Container.puml`.

Почему Spring Batch
- Нативно для Java‑стека TradeWare (низкий порог входа, повторное использование компетенций);
- Готовые паттерны Chunk/Step/Retry/Skip/Partitioning + JobRepository и рестарты;
- Простая интеграция с PostgreSQL, GCS (через SDK), Prometheus/OTel;
- Возможность постепенного выноса ETL из монолита без ломки UI.

### Альтернативы
- Apache Airflow: сильный оркестратор DAG, но требует отдельного кластера и не решает низкоуровневый ETL в Java; уместен как надстройка для многостадийных пайплайнов.
- Apache Beam/Dataflow: мощно для больших объёмов/стриминга, но усложняет стек и требует других компетенций.
- Apache Spark: избыточен для текущих объёмов; полезен при значительном росте и сложной аналитике.
- K8s CronJob + утилиты: достаточно для простых выгрузок, но нет богатой семантики шагов/ретраев/идемпотентности как в Spring Batch.

Недостатки, ограничения, риски
- Поддержка собственного ETL‑сервиса (релизы, миграции схемы BATCH_);
- Тщательная настройка параллелизма, чтобы не перегружать БД;
- Необходимость унифицировать схемы CSV и форматы, валидацию и idempotency;
- В перспективе может потребоваться оркестратор поверх (Airflow/Argo), если пайплайны усложнятся.


