### Задание 2 — Дизайн модуля пакетной выгрузки прайс‑листов

#### Контекст
Каждое утро в 06:00 нужно выгружать кастомные прайс‑листы B2B‑клиентов (CSV/XLS) на основе текущих данных в PostgreSQL. Объём выборки 5–10 тыс. строк, без сложной бизнес‑трансформации — по сути join таблиц `products`, `categories`, `clients`, `client_prices` и фильтрация по активным клиентам/товарам.

---

### Выбор технологического решения
Рассмотрены варианты: Spring Batch, Apache Airflow, Kubernetes Job/CronJob, Apache Spark.

| Критерий | Spring Batch | Apache Airflow | K8s CronJob | Apache Spark |
|---|---|---|---|---|
| Наличие CRON‑расписания | Через Spring Scheduler/Quartz или запуском в K8s CronJob | Встроенный сложный планировщик/оркестратор | Встроенное CRON расписание объекта `CronJob` | Не про планирование, требует внешнего планировщика |
| Сложность реализации логики обработки | Низкая/средняя: готовые `ItemReader/Writer` для JDBC/CSV, шаги | Низкая для оркестрации, логику всё равно писать отдельно | Низкая: контейнер запускает любой скрипт/приложение | Избыточна: рассчитан на большие объёмы и сложные трансформации |
| Ресурсоёмкость | Низкая для 5–10k строк | Средняя: поднимается веб‑сервер, БД метаданных, воркеры | Низкая: старт пода по расписанию | Высокая (даже в локальном режиме) |
| Масштабируемость и сложность | Хорошо масштабируется горизонтально (параллельные шаги), но избыточно здесь | Отличная оркестрация дагов, но избыточно для одной простой задачи | Масштабируемость за счёт ресурсов пода и параллелизма контейнера | Отличная для больших данных, избыточно |
| Развёртывание и интеграция с микросервисами | Нативно в Spring‑экосистеме; легко завернуть в контейнер | Требует отдельного кластера Airflow и DevOps‑настройки | Нативно для k8s‑инфры; минимум компонентов | Требует Spark‑кластера/оператора |
| Интеграция с логированием/мониторингом | Легко подключить `Micrometer`, `Prometheus`, `ELK`, `OpenTelemetry` | Есть собственные метрики+интеграции, но сложнее поддержка | Логи пода попадают в существующий стек; метрики через sidecar/экспортер | Есть метрики, но сложнее и тяжелее стек |

Вывод: для задачи «каждое утро выполнить простой SQL‑join и выгрузить ~10k строк в CSV/XLS» оптимально использовать «тонкий» контейнер со служебной утилитой/приложением, запускаемый по расписанию `Kubernetes CronJob`. Бизнес‑логика минимальна, тяжёлые фреймворки (Airflow/Spark) избыточны. Если в компании стандартизирована Java/Spring‑экосистема, реализацию можно оформить как небольшое Spring Boot приложение с JDBC и экспортом CSV, но планирование лучше оставить K8s (`CronJob`) — это упрощает эксплуатацию и повторные запуски.

Итоговый выбор: K8s CronJob + легковесное приложение (Java Spring Boot или Python) для чтения из Postgres и записи CSV/XLS в объектное хранилище (S3/MinIO) или общий volume.

---

### C4 — Контекстная диаграмма To‑Be (уровень System Context)
Участники и взаимодействия:
- Пользователь системы (B2B‑клиент): получает прайс‑лист по ссылке/из почты (вне контура задачи).
- Сервис «Batch Price Export» (контейнер/образ): читает данные из `PostgreSQL` и генерирует файлы.
- `Kubernetes CronJob`: планирует запуск контейнера ежедневно в 06:00.
- `PostgreSQL` (в k8s или управляема в облаке): источник данных (`products`, `categories`, `clients`, `client_prices`).
- Объектное хранилище (S3/MinIO) или `PersistentVolume`: место выгрузки файлов.
- Логирование/мониторинг: `stdout` → `ELK`/`Loki`; метрики → `Prometheus`/`Grafana`; алерты → `Alertmanager`.

Потоки:
1) В 06:00 `CronJob` создаёт `Job`, который поднимает под с контейнером `price-exporter`.
2) Приложение в контейнере выполняет SQL (join нескольких таблиц) и стримит результат в CSV/XLS.
3) Файлы пишутся в S3/MinIO или в `PVC` и затем доступны downstream‑сервисам (почтовая рассылка, портал).
4) Логи и метрики собираются существующим стеком наблюдаемости.

---

### Высокоуровневый план имплементации и конфигурации

1) Контейнер приложения
- Реализация: вариант A — Java Spring Boot (JDBC, OpenCSV/Apache POI); вариант B — Python (psycopg2 + pandas/xlsxwriter). Для малого объёма достаточно Python.
- Конфигурация подключений через переменные окружения: `PGHOST`, `PGPORT`, `PGDATABASE`, `PGUSER`, `PGPASSWORD`, `OUTPUT_URI` (s3:// или путь к PVC), `FORMAT` (csv/xls), `CLIENT_FILTER` и т.д.
- Логирование в stdout, метрики через `Prometheus` client (HTTP endpoint) или простые счётчики в логах.

2) SQL и экспорт
- Оптимизировать запросы: явные `JOIN` по индексируемым полям, фильтрация по активным сущностям.
- Потоковая выгрузка: курсор/стрим, чтобы не держать все 10k строк в памяти.
- Формат: по умолчанию CSV (разделитель `,`, `UTF‑8`, `;` для региональных требований), опционально XLSX.

3) Хранилище результатов
- Предпочтительно S3/MinIO: версияции, простые TTL‑политики, раздача ссылок.
- Альтернатива: `PersistentVolumeClaim` с ротацией файлов и сторонним сервисом рассылки.

4) Планирование
- Создать ресурс `CronJob` с расписанием `0 6 * * *`, `concurrencyPolicy: Forbid`, `startingDeadlineSeconds: 600`, `successfulJobsHistoryLimit: 3`, `failedJobsHistoryLimit: 5`, `backoffLimit: 2`.
- Передавать секреты БД через `Secret`, конфигурацию — через `ConfigMap`.

5) Наблюдаемость и алертинг
- Аннотации для сбора логов, метрик endpoint `:9090/metrics` (если реализован) или экспорт метрик через логи.
- Алерт при ненулевом коду выхода, пустом файле, количестве записей вне диапазона.

6) Безопасность
- `NetworkPolicy` — доступ из пода только к БД и S3/MinIO.
- `Secret` для учётных данных БД/S3, ротация секретов.
- `readOnlyRootFilesystem`, минимальные привилегии в контейнере.

7) CI/CD
- Сборка образа (Dockerfile multi‑stage), публикация в регистри.
- Манифесты K8s (Helm/Kustomize) — окружения dev/stage/prod, параметры расписания.
- Интеграционные тесты запроса к БД и сверка формата CSV.

8) Обработка ошибок и повторные запуски
- Идемпотентные имена файлов с датой: `prices_YYYY‑MM‑DD_client.csv`.
- В случае сбоя — `Job` перезапускается согласно `backoffLimit`, можно инициировать ручной повторный запуск.

---

### Почему не Airflow / не Spark / и когда рассмотреть их
- Airflow целесообразен при множестве связанных задач, ветвлениях, зависимостях, SLA и потребности в веб‑UI оркестрации. Для одной простой ежедневной выгрузки — повышает операционные расходы.
- Spark оправдан при объёмах на порядки больше, сложных агрегациях и необходимости распределённой обработки. Для 10k строк — избыточен.
- Spring Batch добавляет инфраструктуру шагов/ретраев/партиционирования, полезно при усложнении пайплайна; на старт — лишний слой. Его можно добавить позже внутри того же контейнера, если логика вырастет.

---

### Короткое описание работы решения
Ежедневно в 06:00 `Kubernetes CronJob` поднимает контейнер `price-exporter`. Контейнер выполняет параметризованный SQL‑запрос к `PostgreSQL`, стримит данные в CSV/XLS и складывает файл в S3/MinIO (или PVC). Логи и метрики собираются стандартным стеком наблюдаемости. В случае сбоя срабатывает ретрай `Job` и отправляется алерт.
